@article{dataset,
	title = {The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients},
	journal = {Expert Systems with Applications},
	volume = {36},
	number = {2, Part 1},
	pages = {2473-2480},
	year = {2009},
	issn = {0957-4174},
	doi = {https://doi.org/10.1016/j.eswa.2007.12.020},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417407006719},
	author = {I-Cheng Yeh and Che-hui Lien},
	keywords = {Banking, Neural network, Probability, Data mining},
	abstract = {This research aimed at the case of customers’ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel “Sorting Smoothing Method” to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y=A+BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.}
}
@misc{kaggle,
	title = {Default of Credit Card Clients Dataset},
	howpublished = {\url{https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset}},
	note = {Accessed: 2023-01-23}
}
@misc{grid,
title = {How to Grid Search Hyperparameters for Deep Learning Models in Python with Keras},
howpublished={\url{https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/}},
note = {Accessed: 2023-01-25}
}
@article{python,
	author={Oliphant, Travis E.},
	journal={Computing in Science and Engineering}, 
	title={Python for Scientific Computing}, 
	year={2007},
	volume={9},
	number={3},
	pages={10-20},
	doi={10.1109/MCSE.2007.58}}
@InProceedings{ scipy,
	author    = { {W}es {M}c{K}inney },
	title     = { {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython },
	booktitle = { {P}roceedings of the 9th {P}ython in {S}cience {C}onference },
	pages     = { 56 - 61 },
	year      = { 2010 },
	editor    = { {S}t\'efan van der {W}alt and {J}arrod {M}illman },
	doi       = { 10.25080/Majora-92bf1922-00a }
}
@article{scikit,
	author  = {Fabian Pedregosa and Ga{{\"e}}l Varoquaux and Alexandre Gramfort and Vincent Michel and Bertrand Thirion and Olivier Grisel and Mathieu Blondel and Peter Prettenhofer and Ron Weiss and Vincent Dubourg and Jake Vanderplas and Alexandre Passos and David Cournapeau and Matthieu Brucher and Matthieu Perrot and {{\'E}}douard Duchesnay},
	title   = {Scikit-learn: Machine Learning in Python},
	journal = {Journal of Machine Learning Research},
	year    = {2011},
	volume  = {12},
	number  = {85},
	pages   = {2825-2830},
	url     = {http://jmlr.org/papers/v12/pedregosa11a.html}
}
@misc{tfKeras,
	author = {},
	title = {{G}it{H}ub - tensorflow/tensorflow: {A}n {O}pen {S}ource {M}achine {L}earning {F}ramework for {E}veryone --- github.com},
	howpublished = {\url{https://github.com/tensorflow/tensorflow}},
	year = {},
	note = {Accessed: 2023-01-27},
}



